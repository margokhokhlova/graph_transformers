{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks\n",
    "This demo shows the performance of other SOTA graph embeddings methods and their limitations:\n",
    "they do not take attributes into account (only can handle discreet attributes)\n",
    "they are very dependable onto the reinitialization of the random walks and minor graph changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "sys.path.append(os.path.realpath('lib'))\n",
    "from lib.data_loader import load_local_data\n",
    "from benchmarks.sub2vec import Sub2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sub2vec demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vects  2000\n",
      "(2000, 128)\n"
     ]
    }
   ],
   "source": [
    "dataset_n='aids'\n",
    "path='data/'\n",
    "X,y=load_local_data(path,dataset_n, attributes=False, use_node_deg=False)\n",
    "sub2vec = Sub2vec(property='s', walkLength=100, output='aids_walk', d=128, iter=100, windowSize=2, p=0.5, model='dm')\n",
    "sub2vec.obtainRandomWalks(X)\n",
    "embeddings = sub2vec.calculateEmbeddings()\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-calculate the embeddings and demonstrate that the cosine similarity doesn't work within rounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vects  2000\n"
     ]
    }
   ],
   "source": [
    "sub2vec.obtainRandomWalks(X)\n",
    "embeddings2 = sub2vec.calculateEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two graphs within rounds is [[-0.02972129]]\n",
      "Similarity of two graphs within rounds is [[-0.00695749]]\n",
      "Similarity of two graphs within rounds is [[0.18097776]]\n",
      "Similarity of two graphs within rounds is [[-0.0468096]]\n",
      "Similarity of two graphs within rounds is [[-0.0196318]]\n",
      "Similarity of two graphs within rounds is [[0.0975268]]\n",
      "Similarity of two graphs within rounds is [[-0.0731004]]\n",
      "Similarity of two graphs within rounds is [[0.06960186]]\n",
      "Similarity of two graphs within rounds is [[0.00319865]]\n",
      "Similarity of two graphs within rounds is [[-0.16390699]]\n"
     ]
    }
   ],
   "source": [
    "# display cosine similarity for first 10 embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "num_graphs, d = embeddings.shape\n",
    "random_graphs =  np.random.randint(0, num_graphs, size=(10))\n",
    "for i in random_graphs:\n",
    "    print(f\"Similarity of two graphs within rounds is {cosine_similarity(embeddings[i,:].reshape(1, -1), embeddings2[i,:].reshape(1, -1))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now calculate the embeddings in one go and check whether they are similar or not this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_double = np.hstack((X,X))\n",
    "sub2vec.obtainRandomWalks(X_double)\n",
    "embeddings1_2 = sub2vec.calculateEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two graphs from the same round is [[0.9879497]]\n",
      "Similarity of two graphs from the same round is [[0.97967386]]\n",
      "Similarity of two graphs from the same round is [[0.9444059]]\n",
      "Similarity of two graphs from the same round is [[0.9886148]]\n",
      "Similarity of two graphs from the same round is [[0.3091755]]\n",
      "Similarity of two graphs from the same round is [[0.97971815]]\n",
      "Similarity of two graphs from the same round is [[0.981849]]\n",
      "Similarity of two graphs from the same round is [[0.5953318]]\n",
      "Similarity of two graphs from the same round is [[0.9656513]]\n",
      "Similarity of two graphs from the same round is [[0.98958343]]\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = embeddings1_2[:2000,:]\n",
    "embeddings2 = embeddings1_2[2000:,:]\n",
    "num_graphs, d = embeddings1.shape\n",
    "random_graphs =  np.random.randint(0, num_graphs, size=(10))\n",
    "for i in random_graphs:\n",
    "    print(f\"Similarity of two graphs from the same round is {cosine_similarity(embeddings1[i,:].reshape(1, -1), embeddings2[i,:].reshape(1, -1))}\")\n",
    "# much better but still very small at times, not consistent and these are the same graphs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I modified the graphs removing one single (always connected only to one or max two neighbors node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def remove_single_node(graphs_list):\n",
    "    ''' function just removes a random node from a graph which has one or two neighbors'''\n",
    "    modified_graphs = []\n",
    "    for graph in graphs_list:\n",
    "        nx_graph = graph.nx_graph # get the graph\n",
    "        degree = nx_graph.degree\n",
    "        degreeDict = dict(degree)\n",
    "        random_nodes_to_delete = []\n",
    "        # pick nodes which have 1 neighbor only\n",
    "        for node, degree in degreeDict.items():\n",
    "            if degree == 1:\n",
    "                random_nodes_to_delete.append(node)\n",
    "        # else pick nodes which have 2 neighbors\n",
    "        if len(random_nodes_to_delete) == 0:\n",
    "            for node, degree in degreeDict.items():\n",
    "                if degree == 2:\n",
    "                    random_nodes_to_delete.append(node)\n",
    "        if len(random_nodes_to_delete)==0:\n",
    "            modified_graphs.append(graph) # leave the graph as it was\n",
    "            print('A graph which has no nodes with degrees 1 & 2 detected')\n",
    "        else:\n",
    "            copy_graph = deepcopy(graph) # create a new deep copy\n",
    "            copy_graph.nx_graph.remove_node(random.choice(random_nodes_to_delete))\n",
    "\n",
    "            modified_graphs.append(copy_graph)\n",
    "        #\n",
    "    return modified_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "graph before modif has 47 and after modif 46\n",
      "graph before modif has 11 and after modif 10\n",
      "graph before modif has 9 and after modif 8\n",
      "graph before modif has 10 and after modif 9\n",
      "graph before modif has 16 and after modif 15\n",
      "graph before modif has 9 and after modif 8\n",
      "graph before modif has 11 and after modif 10\n",
      "graph before modif has 10 and after modif 9\n",
      "graph before modif has 17 and after modif 16\n",
      "graph before modif has 9 and after modif 8\n"
     ]
    }
   ],
   "source": [
    "# a small unit test of a function above\n",
    "subset_X = X[:10]\n",
    "modified_subset = remove_single_node(subset_X)\n",
    "print('done')\n",
    "for i in range(10):\n",
    "    print(f\"graph before modif has {len(subset_X[i].nx_graph)} and after modif {len(modified_subset[i].nx_graph)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now check if the resulting embeddings are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vects  4000\n"
     ]
    }
   ],
   "source": [
    "X_modified =  remove_single_node(X)\n",
    "X_original_and_modidied = np.hstack((X,X_modified))\n",
    "sub2vec.obtainRandomWalks(X_original_and_modidied)\n",
    "embeddings1_2 = sub2vec.calculateEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two graphs with a single node removed is [[0.86806303]]\n",
      "Similarity of two graphs with a single node removed is [[0.94509435]]\n",
      "Similarity of two graphs with a single node removed is [[0.73967075]]\n",
      "Similarity of two graphs with a single node removed is [[0.9920117]]\n",
      "Similarity of two graphs with a single node removed is [[0.91278666]]\n",
      "Similarity of two graphs with a single node removed is [[0.99589455]]\n",
      "Similarity of two graphs with a single node removed is [[0.66772443]]\n",
      "Similarity of two graphs with a single node removed is [[0.65350485]]\n",
      "Similarity of two graphs with a single node removed is [[0.69574]]\n",
      "Similarity of two graphs with a single node removed is [[0.83128214]]\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = embeddings1_2[:2000,:]\n",
    "embeddings2 = embeddings1_2[2000:,:]\n",
    "num_graphs, d = embeddings1.shape\n",
    "random_graphs =  np.random.randint(0, num_graphs, size=(10))\n",
    "for i in random_graphs:\n",
    "    print(f\"Similarity of two graphs with a single node removed is {cosine_similarity(embeddings1[i,:].reshape(1, -1), embeddings2[i,:].reshape(1, -1))}\")\n",
    "# sometimes the change is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion Sub2Vec\n",
    "The results are not too bad, however, for some cases it is still a lot for the case when we need to compare the vectors. A complete disaster between runs - the embeddings are not coherent at all. Affected quite a lot by the random walk. \n",
    "And the main problem with this method - we cannot really use the attributes which are [potentially] extremely important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph2Vec demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import hashlib\n",
    "import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from benchmarks.graph2vec import feature_extractor # I modified the original code by the authors to directly use it on our data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature extraction started.\n",
      "\n",
      "\n",
      "Optimization started.\n",
      "\n",
      "Returned embeddings shape is (2000, 128)\n"
     ]
    }
   ],
   "source": [
    "dataset_n = 'aids'\n",
    "path = 'data/'\n",
    "X, y = load_local_data(path, dataset_n, attributes=False, use_node_deg=False)\n",
    "X = list(X)\n",
    "print(\"\\nFeature extraction started.\\n\")\n",
    "document_collections = Parallel(n_jobs=1)(delayed(feature_extractor)(g,2, str(i)) for i, g in enumerate(X))\n",
    "print(\"\\nOptimization started.\\n\")\n",
    "\n",
    "model = Doc2Vec(document_collections, vector_size = 128, window = 2, min_count = 5, dm = 0,\n",
    "                sample = 0.0001, workers = 10, epochs = 20, alpha =0.025)\n",
    "embeddings = model.docvecs.vectors_docs\n",
    "print(f\"Returned embeddings shape is {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_collections2 = Parallel(n_jobs=1)(delayed(feature_extractor)(g,2, str(i)) for i, g in enumerate(X))\n",
    "model = Doc2Vec(document_collections2, vector_size = 128, window = 2, min_count = 5, dm = 0,\n",
    "                sample = 0.0001, workers = 10, epochs = 20, alpha =0.025)\n",
    "embeddings2 = model.docvecs.vectors_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the similarity within the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two graphs within rounds is [[0.7764359]]\n",
      "Similarity of two graphs within rounds is [[0.84474015]]\n",
      "Similarity of two graphs within rounds is [[0.8015995]]\n",
      "Similarity of two graphs within rounds is [[0.8488554]]\n",
      "Similarity of two graphs within rounds is [[0.49738064]]\n",
      "Similarity of two graphs within rounds is [[0.8559578]]\n",
      "Similarity of two graphs within rounds is [[0.7632938]]\n",
      "Similarity of two graphs within rounds is [[0.8361054]]\n",
      "Similarity of two graphs within rounds is [[0.78976715]]\n",
      "Similarity of two graphs within rounds is [[0.8290339]]\n"
     ]
    }
   ],
   "source": [
    "num_graphs, d = embeddings.shape\n",
    "random_graphs =  np.random.randint(0, num_graphs, size=(10))\n",
    "for i in random_graphs:\n",
    "    print(f\"Similarity of two graphs within rounds is {cosine_similarity(embeddings[i,:].reshape(1, -1), embeddings2[i,:].reshape(1, -1))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity in a  one run within the same graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_double = np.hstack((X,X))\n",
    "document_collections = Parallel(n_jobs=1)(delayed(feature_extractor)(g,2, str(i)) for i, g in enumerate(X_double))\n",
    "model = Doc2Vec(document_collections, vector_size = 128, window = 2, min_count = 5, dm = 0,\n",
    "                sample = 0.0001, workers = 10, epochs = 20, alpha =0.025)\n",
    "embeddings1_2 = model.docvecs.vectors_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two graphs from the same round is [[0.9953762]]\n",
      "Similarity of two graphs from the same round is [[0.99253607]]\n",
      "Similarity of two graphs from the same round is [[0.9720104]]\n",
      "Similarity of two graphs from the same round is [[0.98403585]]\n",
      "Similarity of two graphs from the same round is [[0.9915637]]\n",
      "Similarity of two graphs from the same round is [[0.9915637]]\n",
      "Similarity of two graphs from the same round is [[0.9949548]]\n",
      "Similarity of two graphs from the same round is [[0.98219454]]\n",
      "Similarity of two graphs from the same round is [[0.9917908]]\n",
      "Similarity of two graphs from the same round is [[0.984567]]\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = embeddings1_2[:2000,:]\n",
    "embeddings2 = embeddings1_2[2000:,:]\n",
    "num_graphs, d = embeddings1.shape\n",
    "random_graphs =  np.random.randint(0, num_graphs, size=(10))\n",
    "for i in random_graphs:\n",
    "    print(f\"Similarity of two graphs from the same round is {cosine_similarity(embeddings1[i,:].reshape(1, -1), embeddings2[i,:].reshape(1, -1))}\")\n",
    "# this actually looks pretty good! So the WL labeling gives pretty good results in comparison with random walks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, check if the algo is robust for node removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified =  remove_single_node(X)\n",
    "X_original_and_modidied = np.hstack((X,X_modified))\n",
    "document_collections = Parallel(n_jobs=1)(delayed(feature_extractor)(g,2, str(i)) for i, g in enumerate(X_original_and_modidied))\n",
    "model = Doc2Vec(document_collections, vector_size = 128, window = 2, min_count = 5, dm = 0,\n",
    "                sample = 0.0001, workers = 10, epochs = 20, alpha =0.025)\n",
    "embeddings1_2 = model.docvecs.vectors_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two graphs from the same round is [[0.83382845]]\n",
      "Similarity of two graphs from the same round is [[0.9170121]]\n",
      "Similarity of two graphs from the same round is [[0.60226]]\n",
      "Similarity of two graphs from the same round is [[0.6322068]]\n",
      "Similarity of two graphs from the same round is [[0.7120235]]\n",
      "Similarity of two graphs from the same round is [[0.16714764]]\n",
      "Similarity of two graphs from the same round is [[0.5319908]]\n",
      "Similarity of two graphs from the same round is [[0.80314404]]\n",
      "Similarity of two graphs from the same round is [[0.8657018]]\n",
      "Similarity of two graphs from the same round is [[0.83312845]]\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = embeddings1_2[:2000,:]\n",
    "embeddings2 = embeddings1_2[2000:,:]\n",
    "num_graphs, d = embeddings1.shape\n",
    "random_graphs =  np.random.randint(0, num_graphs, size=(10))\n",
    "for i in random_graphs:\n",
    "    print(f\"Similarity of two graphs from the same round is {cosine_similarity(embeddings1[i,:].reshape(1, -1), embeddings2[i,:].reshape(1, -1))}\")\n",
    "# this actually looks pretty good! So the WL labeling gives pretty good results in comparison with random walks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not really robust to this one, so this is a limitation of graph2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion on two embedding methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It will be awesome to allow to use node attributes of graphs in resulting embeddings.\n",
    "It will be nice to have constant embeddings withing algorithm run but in the same moment to make them robust for minor graph \n",
    "changes. There are methods which allow for that (for example, subgraph mathcing kernel) - but they way too long to compute for a real-case scenario.\n",
    "If we could have had a "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
